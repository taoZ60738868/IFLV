#!/bin/sh

# IFLV EPG更新脚本
# 版本: 1.1.0
# 支持功能: 多源自动获取、本地缓存、增量更新、自动频道匹配、智能数据解析
#
# 参考项目致谢:
# - EPG解析引擎参考: https://github.com/Guovin/iptv-api/
# - 频道匹配算法参考: https://github.com/super321/iptv-tool
# - XML数据处理优化参考: https://github.com/gyssi007/-IPTV-/

# 设置颜色输出
COLOR_INFO='\033[0;32m'
COLOR_WARN='\033[0;33m'
COLOR_ERROR='\033[0;31m'
COLOR_DEBUG='\033[0;34m'
COLOR_NC='\033[0m' # 无颜色

# 常量定义
EPG_DIR="/usr/share/iflv/epg"
BACKUP_DIR="/usr/share/iflv/epg/backup"
TEMP_DIR="/tmp/iflv_epg_temp"
LOCK_FILE="/var/run/iflv_epg.lock"
LOG_FILE="/var/log/iflv.log"
CONFIG_FILE="/etc/config/iflv"
CHANNELS_FILE="/usr/share/iflv/channels.json"
STATS_FILE="${EPG_DIR}/stats.json"

# 创建必要的目录
mkdir -p $EPG_DIR
mkdir -p $BACKUP_DIR
mkdir -p $TEMP_DIR

# 日志函数
log() {
    local level="$1"
    local message="$2"
    local color="$COLOR_NC"
    
    case "$level" in
        "info") color="$COLOR_INFO" ;;
        "warn") color="$COLOR_WARN" ;;
        "error") color="$COLOR_ERROR" ;;
        "debug") color="$COLOR_DEBUG" ;;
    esac
    
    # 输出到控制台
    echo -e "${color}[IFLV-EPG] $(date '+%Y-%m-%d %H:%M:%S') $level: $message${COLOR_NC}"
    
    # 记录到日志文件
    echo "[IFLV-EPG] $(date '+%Y-%m-%d %H:%M:%S') $level: $message" >> "$LOG_FILE"
}

# 检查锁文件
check_lock() {
    if [ -f "$LOCK_FILE" ]; then
        local pid=$(cat "$LOCK_FILE")
        if kill -0 "$pid" 2>/dev/null; then
            log "warn" "已经有一个EPG更新进程在运行 (PID: $pid)"
            
            # 检查锁文件创建时间，如果超过6小时，可能是僵尸进程
            local lock_time=$(stat -c %Y "$LOCK_FILE")
            local current_time=$(date +%s)
            local diff=$(( current_time - lock_time ))
            
            if [ $diff -gt 21600 ]; then
                log "warn" "锁文件超过6小时，可能是僵尸进程，尝试强制删除"
                rm -f "$LOCK_FILE"
                echo $$ > "$LOCK_FILE"
                return 0
            else
                return 1
            fi
        else
            log "warn" "发现过期的锁文件，正在删除"
            rm -f "$LOCK_FILE"
        fi
    fi
    
    # 创建锁文件
    echo $$ > "$LOCK_FILE"
    log "debug" "创建锁文件，PID: $$"
    return 0
}

# 清理函数
cleanup() {
    log "debug" "清理临时文件和锁文件"
    rm -rf "$TEMP_DIR"
    rm -f "$LOCK_FILE"
}

# 设置信号处理
trap cleanup EXIT INT TERM

# 获取配置
fetch_config() {
    log "info" "读取EPG配置信息"
    
    # 加载UCI配置
    . /lib/functions.sh
    config_load 'iflv'
    
    # 获取EPG配置信息
    local enabled
    local interval_hours
    local sources
    local cache_days
    local auto_match
    local preferred_language
    local max_program_days
    
    config_get enabled epg enabled "1"
    config_get interval_hours epg interval "24"
    config_get sources epg sources ""
    config_get cache_days epg cache_days "7"
    config_get auto_match epg auto_match "1"
    config_get preferred_language epg preferred_language "cn"
    config_get max_program_days epg max_program_days "7"
    
    if [ "$enabled" != "1" ]; then
        log "info" "EPG功能未启用"
        exit 0
    fi
    
    INTERVAL_HOURS="$interval_hours"
    EPG_SOURCES="$sources"
    CACHE_DAYS="$cache_days"
    AUTO_MATCH="$auto_match"
    PREFERRED_LANGUAGE="$preferred_language"
    MAX_PROGRAM_DAYS="$max_program_days"
    
    log "info" "EPG配置: 间隔=${INTERVAL_HOURS}小时, 缓存=${CACHE_DAYS}天, 自动匹配=${AUTO_MATCH}, 语言=${PREFERRED_LANGUAGE}, 最大节目天数=${MAX_PROGRAM_DAYS}"
}

# 检查更新间隔
check_update_interval() {
    local force="$1"
    
    if [ "$force" = "1" ]; then
        log "info" "强制更新EPG"
        return 0
    fi
    
    # 检查上次更新时间
    local last_update_file="${EPG_DIR}/last_update"
    if [ -f "$last_update_file" ]; then
        local last_update=$(cat "$last_update_file")
        local current_time=$(date +%s)
        local diff_hours=$(( (current_time - last_update) / 3600 ))
        
        if [ "$diff_hours" -lt "$INTERVAL_HOURS" ]; then
            log "info" "距离上次更新不足${INTERVAL_HOURS}小时 (${diff_hours}小时), 跳过更新"
            return 1
        else
            log "info" "距离上次更新已超过${INTERVAL_HOURS}小时 (${diff_hours}小时), 开始更新"
        fi
    else
        log "info" "没有找到上次更新记录，执行首次更新"
    fi
    
    return 0
}

# 主函数
main() {
    local force="$1"
    
    # 检查锁文件
    if ! check_lock; then
        exit 1
    fi
    
    # 获取配置
    fetch_config
    
    # 检查更新间隔
    if ! check_update_interval "$force"; then
        exit 0
    fi
    
    # 默认EPG源（如果未配置）
    if [ -z "$EPG_SOURCES" ]; then
        EPG_SOURCES="http://epg.51zmt.top:8000/e.xml.gz http://epg.51zmt.top:8000/cc.xml.gz"
    fi
    
    # 设置缓存天数
    CACHE_DAYS=${CACHE_DAYS:-7}
    
    log "info" "EPG源: $EPG_SOURCES"
    log "info" "缓存天数: $CACHE_DAYS"
    
    # 清理临时目录
    rm -rf "$TEMP_DIR"
    mkdir -p "$TEMP_DIR"
    
    # 下载EPG数据
    local success=0
    local source_count=0
    local download_success=0
    
    for source in $EPG_SOURCES; do
        source_count=$((source_count + 1))
        local file_ext=""
        
        # 根据文件扩展名决定处理方式
        if echo "$source" | grep -q "\.gz$"; then
            file_ext=".xml.gz"
        else
            file_ext=".xml"
        fi
        
        local output_file="${TEMP_DIR}/epg_source_${source_count}${file_ext}"
        
        log "info" "尝试从 $source 下载EPG数据"
        if download_epg_source "$source" "$output_file"; then
            download_success=1
            success=1
        fi
    done
    
    # 如果所有源都下载失败，尝试使用备份
    if [ "$download_success" = "0" ]; then
        log "warn" "所有EPG源下载失败，尝试使用备份"
        
        # 获取最新的备份文件
        local latest_backup=$(ls -t "${BACKUP_DIR}/epg_"*.xml 2>/dev/null | head -n 1)
        
        if [ -n "$latest_backup" ] && [ -f "$latest_backup" ]; then
            log "info" "使用备份文件: $latest_backup"
            cp "$latest_backup" "${TEMP_DIR}/epg_source_backup.xml"
            success=1
        else
            log "error" "没有可用的备份文件"
        fi
    fi
    
    if [ "$success" = "0" ]; then
        log "error" "EPG更新失败: 所有数据源均无法下载"
        exit 1
    fi
    
    # 处理下载的EPG文件
    process_epg_files
    
    # 更新频道匹配（如果启用）
    if [ "$AUTO_MATCH" = "1" ]; then
        auto_match_channels
    fi
    
    # 记录更新时间
    date +%s > "${EPG_DIR}/last_update"
    
    # 更新统计信息
    update_stats
    
    log "info" "EPG更新完成"
    exit 0
}

# 下载EPG源文件
download_epg_source() {
    local url="$1"
    local output_file="$2"
    local success=0
    local start_time=$(date +%s)
    
    # 尝试使用wget下载
    if command -v wget >/dev/null 2>&1; then
        log "debug" "使用wget下载 $url"
        
        if wget -q --timeout=30 --tries=3 -O "$output_file" "$url"; then
            local end_time=$(date +%s)
            local time_taken=$((end_time - start_time))
            log "info" "成功下载 $url (耗时: ${time_taken}秒)"
            success=1
        else
            log "error" "使用wget下载失败: $url"
        fi
    # 如果wget不可用，尝试使用curl
    elif command -v curl >/dev/null 2>&1; then
        log "debug" "使用curl下载 $url"
        
        if curl -s --connect-timeout 30 --retry 3 -o "$output_file" "$url"; then
            local end_time=$(date +%s)
            local time_taken=$((end_time - start_time))
            log "info" "成功下载 $url (耗时: ${time_taken}秒)"
            success=1
        else
            log "error" "使用curl下载失败: $url"
        fi
    else
        log "error" "未找到wget或curl命令，无法下载"
        return 1
    fi
    
    # 检查下载的文件是否有效
    if [ "$success" = "1" ]; then
        # 检查是否需要解压
        if echo "$output_file" | grep -q "\.gz$"; then
            local xml_file="${output_file%.gz}"
            log "debug" "解压 $output_file 到 $xml_file"
            
            if gunzip -c "$output_file" > "$xml_file"; then
                log "info" "成功解压EPG文件"
                rm -f "$output_file"  # 删除压缩文件
                
                # 检查XML文件有效性
                if ! grep -q "<tv" "$xml_file"; then
                    log "error" "解压后的文件不是有效的EPG XML格式"
                    rm -f "$xml_file"
                    return 1
                fi
            else
                log "error" "解压EPG文件失败"
                rm -f "$output_file"
                return 1
            fi
        else
            # 检查XML文件有效性
            if ! grep -q "<tv" "$output_file"; then
                log "error" "下载的文件不是有效的EPG XML格式"
                rm -f "$output_file"
                return 1
            fi
        fi
        
        return 0
    fi
    
    return 1
}

# 处理EPG文件
process_epg_files() {
    log "info" "处理EPG数据文件"
    
    # 获取所有XML文件
    local xml_files=$(find "$TEMP_DIR" -name "*.xml")
    local count=$(echo "$xml_files" | wc -l)
    
    if [ -z "$xml_files" ] || [ "$count" = "0" ]; then
        log "error" "没有找到有效的EPG XML文件"
        return 1
    fi
    
    # 如果只有一个文件，直接使用
    if [ "$count" = "1" ]; then
        log "info" "使用单一EPG数据文件"
        
        # 优化：限制节目日期范围
        optimize_epg_data "$xml_files" "${EPG_DIR}/epg.xml"
        
        # 创建备份
        local backup_file="${BACKUP_DIR}/epg_$(date +%Y%m%d_%H%M%S).xml"
        cp "${EPG_DIR}/epg.xml" "$backup_file"
        log "info" "已创建EPG数据备份: $backup_file"
        
        # 清理旧的备份文件
        find "$BACKUP_DIR" -name "epg_*.xml" -type f -mtime +${CACHE_DAYS} -delete
        
        return 0
    fi
    
    # 如果有多个文件，需要合并
    log "info" "合并多个EPG数据文件"
    
    # 创建合并文件
    local merged_file="${TEMP_DIR}/merged.xml"
    
    # 使用第一个文件作为基础
    local first_file=$(echo "$xml_files" | head -n 1)
    cp "$first_file" "$merged_file"
    
    # 提取频道列表部分
    sed -i -e '/<programme/,$d' -e 's/<\/tv>//g' "$merged_file"
    
    # 合并其他文件的节目信息
    for file in $xml_files; do
        if [ "$file" != "$first_file" ]; then
            # 提取节目信息部分并追加
            sed -n '/<programme/,/<\/tv>/p' "$file" | sed 's/<\/tv>//g' >> "$merged_file"
        fi
    done
    
    # 添加结束标签
    echo "</tv>" >> "$merged_file"
    
    # 优化合并后的EPG数据
    optimize_epg_data "$merged_file" "${EPG_DIR}/epg.xml"
    
    # 创建备份
    local backup_file="${BACKUP_DIR}/epg_$(date +%Y%m%d_%H%M%S).xml"
    cp "${EPG_DIR}/epg.xml" "$backup_file"
    log "info" "已创建EPG数据备份: $backup_file"
    
    # 清理旧的备份文件
    find "$BACKUP_DIR" -name "epg_*.xml" -type f -mtime +${CACHE_DAYS} -delete
    
    return 0
}

# 优化EPG数据 (新增功能)
# 参考: 基于Guovin/iptv-api的数据优化方法，但使用更高效的awk实现
optimize_epg_data() {
    local input_file="$1"
    local output_file="$2"
    
    log "info" "优化EPG数据"
    
    # 创建临时文件
    local temp_output="${TEMP_DIR}/optimized_epg.xml"
    
    # 统计优化前的数据
    local before_size=$(stat -c %s "$input_file")
    local before_programs=$(grep -c "<programme " "$input_file")
    local before_channels=$(grep -c "<channel " "$input_file")
    
    log "debug" "优化前：大小=${before_size}B，节目数=${before_programs}，频道数=${before_channels}"
    
    # 过滤未来MAX_PROGRAM_DAYS天内的节目
    local current_time=$(date +%s)
    local max_time=$((current_time + MAX_PROGRAM_DAYS * 86400))
    local max_date=$(date -d "@$max_time" +"%Y%m%d%H%M%S %z")
    
    # 提取频道部分
    grep -B 1000000 "<programme " "$input_file" | grep -v "<programme " > "$temp_output"
    
    # 保留所有频道信息，但筛选未来一周内的节目
    log "debug" "筛选未来${MAX_PROGRAM_DAYS}天内的节目信息"
    
    # 使用awk处理日期筛选（更高效）
    awk -v max_date="$max_date" '
    /<programme / {
        # 提取start属性
        if (match($0, /start="([^"]+)"/)) {
            start_time = substr($0, RSTART+7, RLENGTH-8);
            if (start_time <= max_date) {
                print;
            }
        } else {
            print;
        }
    }
    !/<programme / && $0 !~ /<\/tv>/ {
        print;
    }
    /<\/tv>/ {
        print "</tv>";
    }
    ' "$input_file" | grep -A 1000000 -m 1 "<programme " >> "$temp_output"
    
    # 确保XML文件以</tv>结尾
    if ! tail -n 1 "$temp_output" | grep -q "</tv>"; then
        echo "</tv>" >> "$temp_output"
    fi
    
    # 为优选语言添加更高的显示优先级
    if [ -n "$PREFERRED_LANGUAGE" ]; then
        log "debug" "优化语言显示优先级：${PREFERRED_LANGUAGE}"
        
        # 创建临时文件进行处理
        local lang_temp="${TEMP_DIR}/lang_temp.xml"
        
        # 使用sed替换语言标记，给首选语言更高的显示优先级
        sed "s/<title lang=\"${PREFERRED_LANGUAGE}\">/<title lang=\"${PREFERRED_LANGUAGE}\" priority=\"high\">/g" "$temp_output" > "$lang_temp"
        mv "$lang_temp" "$temp_output"
    fi
    
    # 统计优化后的数据
    local after_size=$(stat -c %s "$temp_output")
    local after_programs=$(grep -c "<programme " "$temp_output")
    local after_channels=$(grep -c "<channel " "$temp_output")
    
    log "info" "EPG数据优化完成：大小从${before_size}B减少到${after_size}B，节目数从${before_programs}减少到${after_programs}，频道数保持${after_channels}"
    
    # 检查优化后的文件有效性
    if grep -q "<tv" "$temp_output" && grep -q "</tv>" "$temp_output"; then
        mv "$temp_output" "$output_file"
        log "info" "EPG数据优化成功，已保存到 $output_file"
        
        # 计算减少的百分比
        local size_reduction=$((100 - (after_size * 100 / before_size)))
        local program_reduction=$((100 - (after_programs * 100 / before_programs)))
        log "info" "大小减少了${size_reduction}%，节目数减少了${program_reduction}%"
        
        return 0
    else
        log "error" "优化后的EPG数据无效，使用原始数据"
        cp "$input_file" "$output_file"
        return 1
    fi
}

# 自动匹配频道
# 参考: 结合super321/iptv-tool的频道识别算法并增强
auto_match_channels() {
    log "info" "开始自动匹配频道与EPG数据"
    
    if [ ! -f "${EPG_DIR}/epg.xml" ]; then
        log "error" "EPG文件不存在，无法进行频道匹配"
        return 1
    fi
    
    if [ ! -f "$CHANNELS_FILE" ]; then
        log "error" "频道文件不存在，无法进行频道匹配"
        return 1
    fi
    
    # 创建临时文件
    local temp_channels="${TEMP_DIR}/channels.json"
    local epg_channels="${TEMP_DIR}/epg_channels.txt"
    
    # 复制当前频道文件
    cp "$CHANNELS_FILE" "$temp_channels"
    
    # 提取EPG中的频道信息 (增强版)
    grep "<channel id=" "${EPG_DIR}/epg.xml" | sed -E 's/.*id="([^"]*)".*<display-name>([^<]*)<.*/\1|\2/g' > "$epg_channels"
    
    # 提取额外的频道名称别名 (新功能)
    grep -o '<display-name[^>]*>[^<]*</display-name>' "${EPG_DIR}/epg.xml" | sed -E 's/<display-name[^>]*>([^<]*)<\/display-name>/\1/g' | sort | uniq >> "${TEMP_DIR}/channel_aliases.txt"
    
    # 生成匹配脚本 (增强版)
    local match_script="${TEMP_DIR}/match.awk"
    cat > "$match_script" << 'EOF'
BEGIN {
    FS="|";
    while (getline < EPGFILE) {
        split($0, parts, "|");
        epg_id = parts[1];
        epg_name = parts[2];
        epg_ids[epg_name] = epg_id;
        
        # 处理频道名称的别名
        gsub(/[[:space:]]+/, " ", epg_name);  # 规范化空格
        epg_name_lower = tolower(epg_name);   # 转小写以忽略大小写
        epg_ids_lower[epg_name_lower] = epg_id;
        
        # 处理频道名称中的数字（例如将"CCTV1"和"CCTV-1"视为相同）
        normalized = epg_name;
        gsub(/[-_\.]/, "", normalized);      # 移除常见分隔符
        epg_normalized[normalized] = epg_id;
        
        # 为频道名称的每个部分创建索引，以支持部分匹配
        for (i = 0; i < split(epg_name, words, " "); i++) {
            if (length(words[i]) > 1) {
                epg_words[words[i]] = epg_id;
                epg_words[tolower(words[i])] = epg_id;
            }
        }
    }
    
    # 加载频道别名
    while (getline < ALIASFILE) {
        alias = $0;
        if (length(alias) > 1) {
            channel_aliases[alias] = 1;
        }
    }
}

{
    # 保持JSON格式，但尝试添加EPG ID匹配
    if ($0 ~ /"epg_id":/) {
        # 已有EPG ID，检查是否有效
        match($0, /"epg_id":[^,}]*/, epg_match);
        epg_part = epg_match[0];
        if (epg_part ~ /"epg_id":"[^"]*"/ && epg_part !~ /"epg_id":""/) {
            # EPG ID非空且有效，保持不变
            print $0;
        } else {
            # EPG ID为空或无效，尝试匹配
            has_matched = 0;
            
            # 尝试匹配频道名称
            match($0, /"name":"([^"]*)"/, name_match);
            if (length(name_match) > 1) {
                channel_name = name_match[1];
                channel_name_lower = tolower(channel_name);
                channel_normalized = channel_name;
                gsub(/[-_\.]/, "", channel_normalized);
                
                # 多级匹配策略
                if (channel_name in epg_ids) {
                    # 1. 完全匹配
                    sub(/"epg_id":"[^"]*"/, "\"epg_id\":\"" epg_ids[channel_name] "\"");
                    has_matched = 1;
                } else if (channel_name_lower in epg_ids_lower) {
                    # 2. 忽略大小写匹配
                    sub(/"epg_id":"[^"]*"/, "\"epg_id\":\"" epg_ids_lower[channel_name_lower] "\"");
                    has_matched = 1;
                } else if (channel_normalized in epg_normalized) {
                    # 3. 规范化匹配（忽略分隔符）
                    sub(/"epg_id":"[^"]*"/, "\"epg_id\":\"" epg_normalized[channel_normalized] "\"");
                    has_matched = 1;
                } else {
                    # 4. 尝试部分匹配
                    for (word in epg_words) {
                        if (index(channel_name, word) > 0) {
                            sub(/"epg_id":"[^"]*"/, "\"epg_id\":\"" epg_words[word] "\"");
                            has_matched = 1;
                            break;
                        }
                    }
                    
                    # 5. 尝试使用别名匹配
                    if (!has_matched) {
                        for (alias in channel_aliases) {
                            similarity = calculate_similarity(channel_name, alias);
                            if (similarity > 0.8) {  # 相似度阈值
                                for (word in epg_words) {
                                    if (index(alias, word) > 0) {
                                        sub(/"epg_id":"[^"]*"/, "\"epg_id\":\"" epg_words[word] "\"");
                                        has_matched = 1;
                                        break;
                                    }
                                }
                                if (has_matched) break;
                            }
                        }
                    }
                }
            }
            
            print $0;
        }
    } else {
        print $0;
    }
}

# 计算两个字符串的相似度（简化的Levenshtein距离）
function calculate_similarity(str1, str2) {
    len1 = length(str1);
    len2 = length(str2);
    
    if (len1 == 0) return (len2 == 0) ? 1.0 : 0.0;
    if (len2 == 0) return 0.0;
    
    # 计算相同字符数
    same = 0;
    for (i = 1; i <= len1; i++) {
        char = substr(str1, i, 1);
        if (index(str2, char) > 0) same++;
    }
    
    # 返回相似度
    return (same * 2.0) / (len1 + len2);
}
EOF
    
    # 执行匹配
    if command -v awk >/dev/null 2>&1; then
        local matched_channels="${TEMP_DIR}/matched_channels.json"
        awk -v EPGFILE="$epg_channels" -v ALIASFILE="${TEMP_DIR}/channel_aliases.txt" -f "$match_script" "$temp_channels" > "$matched_channels"
        
        # 检查匹配结果
        if [ -s "$matched_channels" ]; then
            # 统计匹配数量
            local before_count=$(grep -c "\"epg_id\":\"[^\"]\+\"" "$temp_channels")
            local after_count=$(grep -c "\"epg_id\":\"[^\"]\+\"" "$matched_channels")
            
            log "info" "EPG频道匹配完成: 之前 $before_count 个匹配，现在 $after_count 个匹配"
            
            if [ "$after_count" -gt "$before_count" ]; then
                # 备份原始频道文件
                cp "$CHANNELS_FILE" "${CHANNELS_FILE}.bak"
                
                # 更新频道文件
                cp "$matched_channels" "$CHANNELS_FILE"
                log "info" "已更新频道文件，新增 $(( after_count - before_count )) 个EPG匹配"
            } else {
                log "info" "没有新的EPG匹配，频道文件保持不变"
            }
        else
            log "error" "频道匹配处理失败"
            return 1
        fi
    else
        log "warn" "未找到awk命令，无法执行频道匹配"
        return 1
    fi
    
    return 0
}

# 更新统计信息 (新功能)
update_stats() {
    log "debug" "更新EPG统计信息"
    
    # 收集统计数据
    local current_time=$(date +%s)
    local epg_size=$(stat -c %s "${EPG_DIR}/epg.xml" 2>/dev/null || echo "0")
    local channels_count=$(grep -c "<channel " "${EPG_DIR}/epg.xml" 2>/dev/null || echo "0")
    local programs_count=$(grep -c "<programme " "${EPG_DIR}/epg.xml" 2>/dev/null || echo "0")
    local backup_count=$(find "$BACKUP_DIR" -name "epg_*.xml" | wc -l)
    
    # 创建统计信息JSON
    cat > "$STATS_FILE" << EOF
{
  "last_update": "$current_time",
  "last_update_human": "$(date -d "@$current_time" "+%Y-%m-%d %H:%M:%S")",
  "epg_size_bytes": "$epg_size",
  "epg_size_human": "$(awk "BEGIN {printf \"%.2f\", $epg_size/1024/1024}")MB",
  "channels_count": "$channels_count",
  "programs_count": "$programs_count",
  "backup_count": "$backup_count",
  "next_update": "$(date -d "@$((current_time + INTERVAL_HOURS * 3600))" "+%Y-%m-%d %H:%M:%S")",
  "sources": [
$(
    # 添加数据源信息
    local first=1
    for source in $EPG_SOURCES; do
        if [ "$first" -eq "1" ]; then
            first=0
        else
            echo ","
        fi
        echo "    {\"url\": \"$source\"}"
    done
)
  ]
}
EOF
    
    log "info" "EPG统计信息已更新：${channels_count}个频道，${programs_count}个节目，大小${epg_size}字节"
}

# 根据参数执行不同操作
case "$1" in
    force)
        main 1
        ;;
    stats)
        # 仅更新统计信息，不下载EPG
        fetch_config
        update_stats
        log "info" "EPG统计信息已更新"
        ;;
    *)
        main 0
        ;;
esac

exit 0 